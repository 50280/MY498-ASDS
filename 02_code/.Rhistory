}
# Apply function to all attributes
all_mfx <- lapply(bridging_attributes, compute_mfx)
# Function to compute marginal effects within each LLM
compute_mfx <- function(attr) {
message("Computing marginal effects for attribute: ", attr)
model <- attribute_models[[attr]]
# Corrected function name
mfx <- marginaleffects::marginal_effects(
model,
variables = "model_fed_q_type",
newdata = datagrid(
model_fed_q_type = c("hobsons_c", "whathow_q"),
model_name = levels(experiment_data$model_name)
)
)
# Add attribute column
mfx$attribute <- attr
return(mfx)
}
# Apply function to all attributes
all_mfx <- lapply(bridging_attributes, compute_mfx)
# Load required package
library(marginaleffects)
# List of bridging attributes
bridging_attributes <- c(
"affinity_experimental", "compassion_experimental", "curiosity_experimental",
"nuance_experimental", "personal_story_experimental",
"reasoning_experimental", "respect_experimental"
)
# Function to compute marginal effect of question type within each LLM
compute_mfx <- function(attr) {
message("Computing marginal effects for attribute: ", attr)
model <- attribute_models[[attr]]
# Use comparisons() instead of marginaleffects()
mfx <- comparisons(
model,
variables = "model_fed_q_type",
newdata = datagrid(
model_fed_q_type = c("hobsons_c", "whathow_q"),
model_name = levels(experiment_data$model_name)  # ensures all LLMs are included
),
by = "model_name"  # tells it to compute marginal effect within each LLM
)
mfx$attribute <- attr
return(mfx)
}
# Apply to all attributes
all_mfx <- lapply(bridging_attributes, compute_mfx)
# Combine into one data frame
mfx_df <- bind_rows(all_mfx)
# Preview results
head(mfx_df)
View(mfx_df)
# Load required package
library(marginaleffects)
# List of bridging attributes
bridging_attributes <- c(
"affinity_experimental", "compassion_experimental", "curiosity_experimental",
"nuance_experimental", "personal_story_experimental",
"reasoning_experimental", "respect_experimental"
)
# Function to compute marginal effect of question type within each LLM
compute_mfx <- function(attr) {
message("Computing marginal effects for attribute: ", attr)
model <- attribute_models[[attr]]
# Use comparisons() instead of marginaleffects()
mfx <- comparisons(
model,
variables = "model_fed_q_type",
newdata = datagrid(
model_fed_q_type = c("whathow_q", "hobsons_c"),
model_name = levels(experiment_data$model_name)  # ensures all LLMs are included
),
by = "model_name"  # tells it to compute marginal effect within each LLM
)
mfx$attribute <- attr
return(mfx)
}
# Apply to all attributes
all_mfx <- lapply(bridging_attributes, compute_mfx)
# Combine into one data frame
mfx_df <- bind_rows(all_mfx)
# Preview results
head(mfx_df)
View(mfx_df)
?inferences
# Load required package
library(marginaleffects)
# List of bridging attributes
bridging_attributes <- c(
"affinity_experimental", "compassion_experimental", "curiosity_experimental",
"nuance_experimental", "personal_story_experimental",
"reasoning_experimental", "respect_experimental"
)
# Function to compute marginal effect of question type within each LLM
library(marginaleffects)
# Function to compute simulated marginal effects for one attribute
compute_simulated_mfx <- function(attr) {
message("Simulating marginal effects for attribute: ", attr)
model <- attribute_models[[attr]]
mfx <- comparisons(
model,
variables = "model_fed_q_type",
newdata = datagrid(
model_fed_q_type = c("hobsons_c", "whathow_q"),
model_name = levels(experiment_data$model_name)
),
by = "model_name",
vcov = "simulation",     # Enable parametric Monte Carlo simulation
iterations = 1000        # Number of Monte Carlo draws
)
mfx$attribute <- attr
return(mfx)
}
# Run for all attributes
simulated_mfx <- lapply(bridging_attributes, compute_simulated_mfx)
# Load required package
library(marginaleffects)
# List of bridging attributes
bridging_attributes <- c(
"affinity_experimental", "compassion_experimental", "curiosity_experimental",
"nuance_experimental", "personal_story_experimental",
"reasoning_experimental", "respect_experimental"
)
# Function to compute marginal effect of question type within each LLM
library(marginaleffects)
compute_simulated_mfx <- function(attr) {
message("Simulating marginal effects for attribute: ", attr)
model <- attribute_models[[attr]]
cmp <- comparisons(
model,
variables = "model_fed_q_type",
newdata = datagrid(
model_fed_q_type = c("hobsons_c", "whathow_q"),
model_name = levels(experiment_data$model_name)
),
by = "model_name"
)
# Use inferences() to apply simulation with custom iterations
sim <- inferences(cmp, method = "simulation", iterations = 1000)
sim$attribute <- attr
return(sim)
}
# Run for all attributes
simulated_mfx <- lapply(bridging_attributes, compute_simulated_mfx)
# Combine into a single dataframe
simulated_mfx_df <- bind_rows(simulated_mfx)
# View preview
head(simulated_mfx_df)
View(simulated_mfx_df)
colnames(simulated_mfx_df)
# General purpose of this document:
# This script implements the inferential analyses for study 2 of the broader project.
# Code written on:
# - R Version: 4.3.1.
# - OS System: macOS Sequoia Version 15.0.1.
################################################################################
# Before you run this script...
################################################################################
# Before running this script, please make sure that you have downloaded the data
# following the instructions on the README file found in the same GitHub
# repository as this script.
# (1) Clear the working space.
rm(list = ls())
# (2) Set your working directory and save it to the object below, or replace getwd()
# with the path to the output directory where you want to save your data.
# wdir <- getwd()
wdir <- "/Users/carolinewagner/Desktop/Local/MY498-capstone-main"
################################################################################
# Directory management.
################################################################################
# In which directory are the data?
ddir <- paste0(wdir, "/01_data")
# Where should the results be saved?
odir <- paste0(ddir, "/10_experimental_results")
################################################################################
# PREREQUISITES
################################################################################
# List of required packages.
needed_packages <- c("tidyverse",
"jsonlite", # jsonlite to read JSON files.
"marginaleffects" # to interpret the results & MC uncertainty
)
# Identify which/whether packages are missing.
missing_packages <- needed_packages[!(needed_packages %in% installed.packages()[, "Package"])]
# Install any missing packages.
if (length(missing_packages) > 0) {
install.packages(missing_packages)
}
# Load all required packages.
invisible(lapply(needed_packages, library, character.only = TRUE))
# Set seed for reproducibility // really important for this script (!!)
set.seed(89)
################################################################################
# Load data with experimental results for study 2
################################################################################
# Define path to the JSONL file
jsonl_path <- paste0(ddir, "/09_experimental_implementation/final_experimental_data.jsonl")
# Read the JSONL file line-by-line and convert to a data frame
experiment_data <- stream_in(file(jsonl_path), verbose = FALSE)
# Remove model_metadata as nested and not required for present analyses
experiment_data$model_metadata <- NULL
# Save
write.csv(simulated_mfx_df, file = file.path(odir, "marginal_effects_main_specification.csv"), row.names = FALSE)
# General purpose of this document:
# This script implements the inferential analyses for study 2 of the broader project.
# Code written on:
# - R Version: 4.3.1.
# - OS System: macOS Sequoia Version 15.0.1.
################################################################################
# Before you run this script...
################################################################################
# Before running this script, please make sure that you have downloaded the data
# following the instructions on the README file found in the same GitHub
# repository as this script.
# (1) Clear the working space.
rm(list = ls())
# (2) Set your working directory and save it to the object below, or replace getwd()
# with the path to the output directory where you want to save your data.
# wdir <- getwd()
wdir <- "/Users/carolinewagner/Desktop/Local/MY498-capstone-main"
################################################################################
# Directory management.
################################################################################
# In which directory are the data?
ddir <- paste0(wdir, "/01_data")
# Where should the results be saved?
odir <- paste0(ddir, "/10_experimental_results")
################################################################################
# PREREQUISITES
################################################################################
# List of required packages.
needed_packages <- c("tidyverse",
"jsonlite", # jsonlite to read JSON files.
"marginaleffects" # to interpret the results & MC uncertainty
)
# Identify which/whether packages are missing.
missing_packages <- needed_packages[!(needed_packages %in% installed.packages()[, "Package"])]
# Install any missing packages.
if (length(missing_packages) > 0) {
install.packages(missing_packages)
}
# Load all required packages.
invisible(lapply(needed_packages, library, character.only = TRUE))
# Set seed for reproducibility // really important for this script (!!)
set.seed(89)
################################################################################
# Load data with experimental results for study 2
################################################################################
# Define path to the JSONL file
jsonl_path <- paste0(ddir, "/09_experimental_implementation/final_experimental_data.jsonl")
# Read the JSONL file line-by-line and convert to a data frame
experiment_data <- stream_in(file(jsonl_path), verbose = FALSE)
# Remove model_metadata as nested and not required for present analyses
experiment_data$model_metadata <- NULL
# (1) Setup categorical variables and reference levels
# Convert to factors with explicit base/reference levels (optional but useful)
experiment_data$model_fed_q_type <- factor(
experiment_data$model_fed_q_type,
levels = c("hobsons_c", "whathow_q") # 'hobsons_c' as reference
)
# (2) Make variable categorical and set gpt-4.1 as a reference because this is the most widely used LLM.
# Make sure its a factor - because input is saved as character strings
experiment_data$model_name <- factor(experiment_data$model_name)
# (3) Then, reorder levels so gpt-4.1 is the reference
experiment_data$model_name <- factor(
experiment_data$model_name,
levels = c("gpt-4.1", setdiff(levels(experiment_data$model_name), "gpt-4.1"))
)
# (1) List of attribute score columns
bridging_attributes <- c(
"affinity_experimental", "compassion_experimental", "curiosity_experimental",
"nuance_experimental", "personal_story_experimental",
"reasoning_experimental", "respect_experimental"
)
# (2) Function to fit model for one attribute
fit_model <- function(attr_name) {
message("Fitting model for attribute: ", attr_name)
formula <- as.formula(paste(attr_name, "~ model_fed_q_type * model_name"))
lm(formula, data = experiment_data)
}
# (3) Fit models for all attributes and store them
attribute_models <- lapply(bridging_attributes, fit_model)
names(attribute_models) <- bridging_attributes
# Load required package
library(marginaleffects)
# List of bridging attributes
bridging_attributes <- c(
"affinity_experimental", "compassion_experimental", "curiosity_experimental",
"nuance_experimental", "personal_story_experimental",
"reasoning_experimental", "respect_experimental"
)
# Function to compute marginal effect of question type within each LLM
library(marginaleffects)
compute_simulated_mfx <- function(attr) {
message("Simulating marginal effects for attribute: ", attr)
model <- attribute_models[[attr]]
cmp <- comparisons(
model,
variables = "model_fed_q_type",
newdata = datagrid(
model_fed_q_type = c("hobsons_c", "whathow_q"),
model_name = levels(experiment_data$model_name)
),
by = "model_name"
)
# Use inferences() to apply simulation with custom iterations as described in package documentation
sim <- inferences(cmp, method = "simulation", iterations = 1000)
sim$attribute <- attr
return(sim)
}
# Run for all attributes
simulated_mfx <- lapply(bridging_attributes, compute_simulated_mfx)
# Combine into a single dataframe
simulated_mfx_df <- bind_rows(simulated_mfx)
# Save
write.csv(simulated_mfx_df, file = file.path(odir, "marginal_effects_main_specification.csv"), row.names = FALSE)
# Load required package
library(lme4)
# (1) List of attribute score columns
bridging_attributes <- c(
"affinity_experimental", "compassion_experimental", "curiosity_experimental",
"nuance_experimental", "personal_story_experimental",
"reasoning_experimental", "respect_experimental"
)
# (2) Function to fit mixed-effects model for one attribute
fit_mixed_model <- function(attr_name) {
message("Fitting mixed-effects model for attribute: ", attr_name)
# Create formula with random intercept for utterance_id
formula <- as.formula(paste(attr_name, "~ model_fed_q_type * model_name + (1 | utterance_id)"))
# Fit the model using lmer
lmer(formula, data = experiment_data)
}
# (3) Fit models for all attributes and store them
attribute_models <- lapply(bridging_attributes, fit_mixed_model)
names(attribute_models) <- bridging_attributes
# Run marginal effects computation using the pre-defined function
simulated_mfx <- lapply(bridging_attributes, compute_simulated_mfx)
# Load required package
library(lme4)
# (1) Function to fit mixed-effects model for one attribute
fit_mixed_model_secondary <- function(attr_name) {
message("Fitting mixed-effects model for attribute: ", attr_name)
# Create formula with random intercept for utterance_id
formula <- as.formula(paste(attr_name, "~ model_fed_q_type * model_name + (1 | utterance_id)"))
# Fit the model using lmer
lmer(formula, data = experiment_data)
}
# (2) Fit models for all attributes and store in new object
attribute_models_secondary <- lapply(bridging_attributes, fit_mixed_model_secondary)
names(attribute_models_secondary) <- bridging_attributes
# To note about the uncertainty estimates here. The marginaleffects package by default only accounts for uncertainty in the fixed effects, and not the random effects when computing standard errors or simulations.
# So in these uncertainty estimates, th marginal effects ignore the random effects variance.
# Temporarily point compute_simulated_mfx to the secondary model list
attribute_models <- attribute_models_secondary
# Run marginal effects computation
simulated_mfx_secondary <- lapply(bridging_attributes, compute_simulated_mfx)
# Combine into a single dataframe
simulated_mfx_df_secondary <- bind_rows(simulated_mfx_secondary)
# Save to output directory
write.csv(simulated_mfx_df_secondary,
file = file.path(odir, "marginal_effects_secondary_specification.csv"),
row.names = FALSE)
install.packages("estimatr")
# General purpose of this document:
# This script implements the inferential analyses for study 2 of the broader project.
# Code written on:
# - R Version: 4.3.1.
# - OS System: macOS Sequoia Version 15.0.1.
################################################################################
# Before you run this script...
################################################################################
# Before running this script, please make sure that you have downloaded the data
# following the instructions on the README file found in the same GitHub
# repository as this script.
# (1) Clear the working space.
rm(list = ls())
# (2) Set your working directory and save it to the object below, or replace getwd()
# with the path to the output directory where you want to save your data.
# wdir <- getwd()
wdir <- "/Users/carolinewagner/Desktop/Local/MY498-capstone-main"
################################################################################
# Directory management.
################################################################################
# In which directory are the data?
ddir <- paste0(wdir, "/01_data")
# Where should the results be saved?
odir <- paste0(ddir, "/10_experimental_results")
################################################################################
# PREREQUISITES
################################################################################
# List of required packages.
needed_packages <- c("tidyverse",
"jsonlite", # jsonlite to read JSON files.
"marginaleffects" # to interpret the results & MC uncertainty
)
# Identify which/whether packages are missing.
missing_packages <- needed_packages[!(needed_packages %in% installed.packages()[, "Package"])]
# Install any missing packages.
if (length(missing_packages) > 0) {
install.packages(missing_packages)
}
# Load all required packages.
invisible(lapply(needed_packages, library, character.only = TRUE))
# Set seed for reproducibility // really important for this script (!!)
set.seed(89)
################################################################################
# Load data with experimental results for study 2
################################################################################
# Define path to the JSONL file
jsonl_path <- paste0(ddir, "/09_experimental_implementation/final_experimental_data.jsonl")
# Read the JSONL file line-by-line and convert to a data frame
experiment_data <- stream_in(file(jsonl_path), verbose = FALSE)
# Remove model_metadata as nested and not required for present analyses
experiment_data$model_metadata <- NULL
# (1) Setup categorical variables and reference levels
# Convert to factors with explicit base/reference levels (optional but useful)
experiment_data$model_fed_q_type <- factor(
experiment_data$model_fed_q_type,
levels = c("hobsons_c", "whathow_q") # 'hobsons_c' as reference
)
# (2) Make variable categorical and set gpt-4.1 as a reference because this is the most widely used LLM.
# Make sure its a factor - because input is saved as character strings
experiment_data$model_name <- factor(experiment_data$model_name)
# (3) Then, reorder levels so gpt-4.1 is the reference
experiment_data$model_name <- factor(
experiment_data$model_name,
levels = c("gpt-4.1", setdiff(levels(experiment_data$model_name), "gpt-4.1"))
)
# only if not installed
library(estimatr)
# (1) List of attribute score columns
bridging_attributes <- c(
"affinity_experimental", "compassion_experimental", "curiosity_experimental",
"nuance_experimental", "personal_story_experimental",
"reasoning_experimental", "respect_experimental"
)
fit_model <- function(attr_name) {
message("Fitting model for attribute: ", attr_name)
formula <- as.formula(paste(attr_name, "~ model_fed_q_type * model_name"))
lm_robust(formula, data = experiment_data, clusters = experiment_data$prompt_id)
}
attribute_models <- lapply(bridging_attributes, fit_model)
names(attribute_models) <- bridging_attributes
library(marginaleffects)
compute_simulated_mfx <- function(attr) {
message("Simulating marginal effects for attribute: ", attr)
model <- attribute_models[[attr]]
# Get cluster-robust variance-covariance matrix from lm_robust model
vcov_matrix <- model$vcov
cmp <- comparisons(
model,
variables = "model_fed_q_type",
newdata = datagrid(
model_fed_q_type = c("hobsons_c", "whathow_q"),
model_name = levels(experiment_data$model_name)
),
by = "model_name",
vcov = vcov_matrix  # Pass the clustered vcov here
)
sim <- inferences(cmp, method = "simulation", iterations = 1000)
sim$attribute <- attr
return(sim)
}
# Run for all attributes
simulated_mfx <- lapply(bridging_attributes, compute_simulated_mfx)
# Combine into a single dataframe
simulated_mfx_df <- bind_rows(simulated_mfx)
# Save
write.csv(simulated_mfx_df, file = file.path(odir, "marginal_effects_main_specification_test.csv"), row.names = FALSE)
# only if not installed
library(estimatr)
# (1) List of attribute score columns
bridging_attributes <- c(
"affinity_experimental", "compassion_experimental", "curiosity_experimental",
"nuance_experimental", "personal_story_experimental",
"reasoning_experimental", "respect_experimental"
)
fit_model <- function(attr_name) {
message("Fitting model for attribute: ", attr_name)
formula <- as.formula(paste(attr_name, "~ model_fed_q_type * model_name"))
lm_robust(formula, data = experiment_data, clusters = experiment_data$utterance_id)
}
attribute_models <- lapply(bridging_attributes, fit_model)
names(attribute_models) <- bridging_attributes
library(marginaleffects)
compute_simulated_mfx <- function(attr) {
message("Simulating marginal effects for attribute: ", attr)
model <- attribute_models[[attr]]
# Get cluster-robust variance-covariance matrix from lm_robust model
vcov_matrix <- model$vcov
cmp <- comparisons(
model,
variables = "model_fed_q_type",
newdata = datagrid(
model_fed_q_type = c("hobsons_c", "whathow_q"),
model_name = levels(experiment_data$model_name)
),
by = "model_name",
vcov = vcov_matrix  # Pass the clustered vcov here
)
sim <- inferences(cmp, method = "simulation", iterations = 1000)
sim$attribute <- attr
return(sim)
}
# Run for all attributes
simulated_mfx <- lapply(bridging_attributes, compute_simulated_mfx)
# Combine into a single dataframe
simulated_mfx_df <- bind_rows(simulated_mfx)
# Save
write.csv(simulated_mfx_df, file = file.path(odir, "marginal_effects_main_specification_test.csv"), row.names = FALSE)
