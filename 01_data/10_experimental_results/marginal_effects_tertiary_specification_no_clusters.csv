"term","contrast","model_name","estimate","conf.low","conf.high","attribute"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1",-0.0900817306487133,-0.118710960772269,-0.0574697922836489,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-haiku-20240307",-0.103142254363841,-0.132953733388246,-0.0747194470276634,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-opus-20240229",-0.0888788728524524,-0.119310252970371,-0.0602355906739732,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-sonnet-4-20250514",-0.126755744791564,-0.15744982577356,-0.0959666406009355,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1",-0.0691941003723036,-0.100705520502264,-0.040002771343247,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1-0528-tput",-0.052182951875869,-0.0812383785866229,-0.0234642020455016,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-1.5-pro",-0.0108847938992954,-0.0414227242564792,0.0202744803233288,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-2.5-flash",-0.0663947005271818,-0.0970231251160939,-0.0351403401578769,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-2-27b-it",-0.0388299082764916,-0.0715961574972028,-0.0105533694076939,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-3n-E4B-it",-0.0687344399063117,-0.0970625393950697,-0.0394256746854938,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-mini",-0.0678810311545519,-0.0985457715599967,-0.0398633346162821,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-nano",-0.0816785126674392,-0.113359478653036,-0.0526020508492269,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-3.3-70B-Instruct-Turbo",-0.0511850984976439,-0.0815841176518262,-0.0205648165390437,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-4-Scout-17B-16E-Instruct",-0.0549612910140439,-0.0898831748839243,-0.0226822383131549,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","magistral-medium-2506",-0.0591939653225088,-0.0901353906472834,-0.0268608877133308,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Meta-Llama-3-8B-Instruct-Lite",-0.0738927160469389,-0.101591353941885,-0.0428722622870712,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-medium-latest",-0.0578224096948289,-0.0870550619334103,-0.0284906077818732,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-small",-0.044980631897509,-0.0737049077045352,-0.013274221273339,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","o4-mini",-0.0494392690444866,-0.0819555358042361,-0.0192006835115946,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Qwen2.5-72B-Instruct-Turbo",-0.0490746568407407,-0.0785590087775161,-0.0183943018327093,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","QwQ-32B",-0.061099531245821,-0.0930644101266328,-0.0308498266501823,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1",-0.0776370060491538,-0.107570053921904,-0.0469889223649483,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-haiku-20240307",-0.0593276602065675,-0.0897983365345139,-0.0325427010606076,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-opus-20240229",-0.0494654557166209,-0.0782577733400525,-0.0196381131426532,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-sonnet-4-20250514",-0.0702924491053781,-0.10232193230584,-0.0398203583200594,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1",-0.0424901011288698,-0.0740220435554926,-0.0138387425443089,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1-0528-tput",-0.0347376810023353,-0.062552182413332,-0.00652844212019541,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-1.5-pro",-0.0288122102318482,-0.0571545545805322,-0.000470081720219952,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-2.5-flash",-0.0371429011489353,-0.0660273614203074,-0.00813636476382118,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-2-27b-it",-0.0516487531314037,-0.0799110927191663,-0.0199610351209921,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-3n-E4B-it",-0.0498946888126388,-0.0806880296553247,-0.0216325735858906,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-mini",-0.0550134369273884,-0.0853093664084153,-0.0231056202356289,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-nano",-0.0834179394472998,-0.112482213819427,-0.0530493924529876,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-3.3-70B-Instruct-Turbo",-0.0372661927722986,-0.068412811505427,-0.0077507530200667,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-4-Scout-17B-16E-Instruct",-0.0323093941053805,-0.063769111911682,-0.00134431347643121,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","magistral-medium-2506",-0.0209989851383003,-0.0527248575210843,0.0128877760452817,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Meta-Llama-3-8B-Instruct-Lite",-0.0348040049999913,-0.0654725692573058,-0.00552983382429894,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-medium-latest",-0.0585658241032821,-0.0885638310775753,-0.0276093437160181,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-small",-0.051938184457366,-0.0819791226832147,-0.0230076506011211,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","o4-mini",-0.0304803235433171,-0.0606053945993306,-0.00133982933501513,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Qwen2.5-72B-Instruct-Turbo",-0.050392200658074,-0.0806204060585918,-0.022753395401361,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","QwQ-32B",-0.0532386165872761,-0.0821131711459254,-0.022757032513239,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1",-0.0228488394402676,-0.0445661492214696,-0.00237861961399246,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-haiku-20240307",-0.0513781617793466,-0.0717976420585506,-0.0303488983046794,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-opus-20240229",-0.0468666117892319,-0.0665450433492027,-0.0260610117416861,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-sonnet-4-20250514",-0.0741384632084352,-0.0953461482006208,-0.053910247528212,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1",-0.0204663701789953,-0.0412752043857109,0.00135940287145677,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1-0528-tput",-0.0228076093911036,-0.0416577972973077,-0.00178939680344458,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-1.5-pro",0.0390308384215406,0.0172322850970082,0.0590730140629414,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-2.5-flash",-0.0117731357541421,-0.033395949108117,0.00983506083555539,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-2-27b-it",-0.0353442161638973,-0.057960399973992,-0.0138710243863259,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-3n-E4B-it",-0.0710090442014074,-0.0927105101210023,-0.0487305533610372,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-mini",-0.0738556008524743,-0.0938886667624016,-0.0530983047414515,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-nano",-0.0250348898360667,-0.0455317400318732,-0.00521699123502346,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-3.3-70B-Instruct-Turbo",-0.0367975684741813,-0.0575627731513372,-0.0164326911435674,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-4-Scout-17B-16E-Instruct",-0.0433406763817341,-0.0630361389257964,-0.0215543272711223,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","magistral-medium-2506",-0.0738293756572648,-0.0961935235367276,-0.0510618839973413,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Meta-Llama-3-8B-Instruct-Lite",-0.0576789819882678,-0.0804245146169343,-0.0354761399676757,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-medium-latest",-0.010999108063384,-0.0322645040094896,0.0104939657235514,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-small",-0.00915450046863475,-0.0305116925519271,0.0127994522923453,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","o4-mini",-0.00912285056206563,-0.0297235003883286,0.0128163431089749,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Qwen2.5-72B-Instruct-Turbo",-0.0132768517353697,-0.0338968397110691,0.00777648854360334,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","QwQ-32B",-0.0368959934499927,-0.0569067464969748,-0.0158733118976667,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1",0.0621146447611166,0.0425728405842047,0.0825314301865736,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-haiku-20240307",0.0307873513544564,0.00936042377096716,0.0515514267874508,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-opus-20240229",0.0105798281943721,-0.00790036675597224,0.0289201332935413,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-sonnet-4-20250514",0.010659795334886,-0.00865826555273785,0.0314090147447882,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1",-0.0163755603198155,-0.0351125781549611,0.00252233458612835,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1-0528-tput",0.00386195442622317,-0.0158305970613786,0.0248223372996585,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-1.5-pro",0.0608007864543286,0.0415639942998607,0.0805504777327225,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-2.5-flash",0.0436533343356938,0.023703555367483,0.0635426877393063,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-2-27b-it",0.0385225644650928,0.0187598714927608,0.0592791311765164,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-3n-E4B-it",0.0271015095222416,0.00913767419858587,0.047485173311663,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-mini",0.114388384728342,0.0949653500050367,0.133300636196647,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-nano",0.0981232670351229,0.0779661326837487,0.118105069978031,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-3.3-70B-Instruct-Turbo",0.0281929452910735,0.0072047270790404,0.0464701978959486,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-4-Scout-17B-16E-Instruct",0.0287246706932013,0.00757525344980084,0.0481954818329279,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","magistral-medium-2506",-0.0325481379333056,-0.0548383916246602,-0.0100208062188633,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Meta-Llama-3-8B-Instruct-Lite",0.0435544894788623,0.0252001554167445,0.0637652501488634,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-medium-latest",0.0189164123192416,-0.00249372280454185,0.0387636622961691,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-small",0.0149501877077642,-0.00615721298953649,0.0355908310668356,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","o4-mini",0.0341541426838335,0.0155115458177069,0.0541518638680615,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Qwen2.5-72B-Instruct-Turbo",0.0277381711779784,0.00812962278335378,0.0490638589656255,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","QwQ-32B",0.0330547025334292,0.0132102116665147,0.0518008837019823,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1",-0.0405213491756588,-0.0692398283623241,-0.0103758203202843,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-haiku-20240307",-0.124668193953051,-0.154399509794087,-0.0949032272151152,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-opus-20240229",-0.0701766206112426,-0.0969004701657441,-0.0393332026668365,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-sonnet-4-20250514",-0.0837997535245918,-0.112598599935339,-0.0528068772079562,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1",-0.013792539704057,-0.0440270072024331,0.0164872562323674,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1-0528-tput",-0.0215281805831365,-0.0531673295675689,0.00916474621200935,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-1.5-pro",-0.0140593552576134,-0.0413837156409761,0.0140577561640307,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-2.5-flash",-0.0174610503262423,-0.0466025102273866,0.00988456352338821,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-2-27b-it",-0.0132760979584423,-0.0441727734607912,0.0174090856157946,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-3n-E4B-it",-0.0345333765690837,-0.0628722082452713,-0.00337448702453299,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-mini",-0.0703501898711986,-0.101598910493673,-0.0419783032577978,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-nano",-0.0637319442810294,-0.0956986177163402,-0.0362436775893604,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-3.3-70B-Instruct-Turbo",-0.0322114897464748,-0.0631879191081201,-0.00377316784221935,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-4-Scout-17B-16E-Instruct",-0.044759073629975,-0.077694259031227,-0.0131713068228483,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","magistral-medium-2506",-0.0445901246571005,-0.0734677307501631,-0.0113481139375876,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Meta-Llama-3-8B-Instruct-Lite",-0.0648537491056341,-0.0943076795089496,-0.034437282023478,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-medium-latest",-0.0251909618122054,-0.0543463364466529,0.00442396358940369,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-small",-0.0361218785968787,-0.0643131972854415,-0.00879844404679699,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","o4-mini",-0.0329406086182658,-0.063205147738371,-0.00454192959370693,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Qwen2.5-72B-Instruct-Turbo",-0.0269948835550358,-0.0540038288215229,0.00503055616974812,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","QwQ-32B",-0.0489113163121472,-0.0755930156955995,-0.0196521427330422,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1",0.043245878358307,0.02423781814107,0.0628914463585469,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-haiku-20240307",0.00508382753520897,-0.0145997098907461,0.0241741367018732,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-opus-20240229",-0.00842982774707823,-0.0274428049941821,0.0104992612060943,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-sonnet-4-20250514",-0.00186331346604851,-0.0215776467285259,0.0161616236150919,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1",-0.0223143777422484,-0.0393296406412952,-0.00204149365760716,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1-0528-tput",-0.00280940613583724,-0.021817509966514,0.015745196303167,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-1.5-pro",0.0316952621592481,0.0119197643331479,0.0501897005470044,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-2.5-flash",0.0250601945508252,0.0052342572877671,0.0448282534320453,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-2-27b-it",0.0201755533018176,0.00202543631726767,0.0387628917664303,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-3n-E4B-it",0.0182153911311422,-0.000661239096045332,0.0362696866102858,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-mini",0.086540224517568,0.0663355441455039,0.104232063165349,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-nano",0.0509351008196676,0.0317164372840764,0.0707231315437683,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-3.3-70B-Instruct-Turbo",0.0143722670751133,-0.00601940511264265,0.0327889862729365,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-4-Scout-17B-16E-Instruct",0.0167400207939058,-0.00293343160221794,0.034877525304079,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","magistral-medium-2506",-0.0325470839625963,-0.0546790260828397,-0.0118129630353103,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Meta-Llama-3-8B-Instruct-Lite",0.0262742962394281,0.00700990487769263,0.0443740107897609,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-medium-latest",0.0016525109178358,-0.0170732717140354,0.0206013268756001,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-small",-0.00480270963372398,-0.0237268750878054,0.0153596739775097,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","o4-mini",0.0279992644683789,0.00874376294134527,0.0464676358202396,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Qwen2.5-72B-Instruct-Turbo",0.00327468316627189,-0.0163575230047086,0.0219763026553877,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","QwQ-32B",0.0203933768518714,0.000396558235216891,0.0389373704460169,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1",-0.0595796390632191,-0.073680330132141,-0.0464800900132205,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-haiku-20240307",-0.0552997052816849,-0.0691917155076835,-0.0410685301560761,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-opus-20240229",-0.0452467762529223,-0.0587246051643447,-0.0307641419569814,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-sonnet-4-20250514",-0.0559466473067858,-0.069582092544633,-0.0415426806079553,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1",-0.0439095449880604,-0.0580167275620037,-0.0302746204460317,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1-0528-tput",-0.0372445492037412,-0.0515754203197009,-0.023125792316011,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-1.5-pro",-0.0209895167213093,-0.0357072837596614,-0.00726911375237653,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-2.5-flash",-0.0466714761465675,-0.0612006424062022,-0.0328824528433667,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-2-27b-it",-0.0274430118763968,-0.0408863765336769,-0.0134767461820421,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-3n-E4B-it",-0.0411358137704855,-0.0545190440638756,-0.0275282067174208,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-mini",-0.0445772497892178,-0.0592066558336181,-0.0310117151882459,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-nano",-0.0493132071428523,-0.0637943563390957,-0.0343307659107214,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-3.3-70B-Instruct-Turbo",-0.0302910492018742,-0.0434588358498552,-0.0162329588553587,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-4-Scout-17B-16E-Instruct",-0.0281964580562019,-0.0422456578369805,-0.0142906269094801,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","magistral-medium-2506",-0.0388081436387084,-0.0531659449735633,-0.0241712902188525,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Meta-Llama-3-8B-Instruct-Lite",-0.0351001883098525,-0.0495595666728335,-0.0213582482330134,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-medium-latest",-0.0394095488732356,-0.0537463781216157,-0.0260008086929289,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-small",-0.0357755747244918,-0.0491943855687259,-0.0216748756994224,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","o4-mini",-0.027731153442617,-0.0406439557024635,-0.0136732070733088,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Qwen2.5-72B-Instruct-Turbo",-0.0384191098828995,-0.0529427840353761,-0.0254036425361247,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","QwQ-32B",-0.0394364882691184,-0.0533322395539,-0.0265980467892854,"respect_experimental"
