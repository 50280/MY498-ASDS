"term","contrast","model_name","estimate","conf.low","conf.high","attribute"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1",-0.090081730648277,-0.107690843378191,-0.0699458780797983,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-haiku-20240307",-0.10314225436385,-0.12210688029575,-0.0849386685235449,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-opus-20240229",-0.0888788728524624,-0.107423132250545,-0.0695093951181715,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-sonnet-4-20250514",-0.126755744791567,-0.145404173821135,-0.108466397084006,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1",-0.0691941003723158,-0.0873737769024856,-0.0500338631766394,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1-0528-tput",-0.0521829518758767,-0.0696876469504652,-0.0332133162606062,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-1.5-pro",-0.0108847938992961,-0.0298132044763509,0.00810448081396534,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-2.5-flash",-0.066394700527187,-0.0846993112745352,-0.0467915385771464,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-2-27b-it",-0.0368693801020666,-0.0564353364947319,-0.0171560965434765,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-3n-E4B-it",-0.06873443990632,-0.0881348269248186,-0.0489193241939792,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-mini",-0.0678810311545657,-0.0861811922926025,-0.0497467470054841,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-nano",-0.0816785126674463,-0.0999351940648435,-0.0603053416954935,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-3.3-70B-Instruct-Turbo",-0.0511850984976522,-0.0696415208580808,-0.032142448037904,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-4-Scout-17B-16E-Instruct",-0.0549612910140514,-0.0748333163553382,-0.0354952615403627,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","magistral-medium-2506",-0.0590983359847925,-0.0797613715682094,-0.0390379014355048,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Meta-Llama-3-8B-Instruct-Lite",-0.0738927160469511,-0.091674208957473,-0.0545574753778897,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-medium-latest",-0.0578224096948343,-0.0754004589926071,-0.0382384024496823,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-small",-0.0451136089760469,-0.0641799164928015,-0.0272413834252608,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","o4-mini",-0.0494392690444985,-0.0693672479200866,-0.0317438986863377,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Qwen2.5-72B-Instruct-Turbo",-0.0490746568407489,-0.0658259555933612,-0.0306145364022904,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","QwQ-32B",-0.0609679686163285,-0.0800974235578329,-0.0420924630917766,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1",-0.0776370060486491,-0.0902606324370117,-0.0629779008700467,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-haiku-20240307",-0.0593276602065731,-0.0726349952603495,-0.0457690894573685,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-opus-20240229",-0.0494654557166271,-0.0632802549164443,-0.0358855671619294,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-sonnet-4-20250514",-0.0702924491053877,-0.0824708609510653,-0.0563631066399228,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1",-0.0424901011288805,-0.0565197835090973,-0.0281464429875481,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1-0528-tput",-0.0347376810023432,-0.0485516736207368,-0.0211695391040164,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-1.5-pro",-0.0288122102318521,-0.04327242811231,-0.0159213489770838,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-2.5-flash",-0.0371429011489388,-0.0503531313224965,-0.0227697832568744,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-2-27b-it",-0.0499845536397162,-0.0647494613075901,-0.0357987820049446,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-3n-E4B-it",-0.0498946888126467,-0.0634159235976348,-0.0364921449946303,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-mini",-0.0550134369274001,-0.0680110196987825,-0.040946988016138,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-nano",-0.0834179394473079,-0.0970344596858826,-0.0685680975112561,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-3.3-70B-Instruct-Turbo",-0.037266192772302,-0.0523868789871032,-0.0231474344935157,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-4-Scout-17B-16E-Instruct",-0.0323093941053834,-0.0453858016647566,-0.0183633946477695,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","magistral-medium-2506",-0.0212121404326434,-0.036404167268599,-0.00636559199054425,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Meta-Llama-3-8B-Instruct-Lite",-0.0348040050000012,-0.0483457546009131,-0.021241941368868,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-medium-latest",-0.0585658241032867,-0.0724234798935182,-0.0448053279367161,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-small",-0.0511239323765958,-0.0648521505589914,-0.036467893759128,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","o4-mini",-0.0304803235433277,-0.0435689038671517,-0.016615424742184,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Qwen2.5-72B-Instruct-Turbo",-0.050392200658078,-0.0638988649488262,-0.0370141565273474,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","QwQ-32B",-0.0532112257263035,-0.067395796914168,-0.0390288170355733,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1",-0.0228488394403138,-0.0386143599824243,-0.00629975875589084,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-haiku-20240307",-0.0513781617793426,-0.0675938649514813,-0.0355249993477853,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-opus-20240229",-0.0468666117892282,-0.0639529308417107,-0.0304439829914588,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-sonnet-4-20250514",-0.0741384632084293,-0.089440786758311,-0.0580101470780344,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1",-0.020466370178996,-0.0379508801737161,-0.00453193435778823,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1-0528-tput",-0.022807609391098,-0.0378516855197548,-0.00637615604148851,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-1.5-pro",0.0390308384215441,0.0236797658739349,0.0545165721517181,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-2.5-flash",-0.011773135754135,-0.0288183506290105,0.00444502192725434,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-2-27b-it",-0.0345853792204518,-0.0496884595893502,-0.0174895149933499,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-3n-E4B-it",-0.0710090442014059,-0.0870998543273038,-0.0566894235727219,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-mini",-0.073855600852459,-0.0896908773633698,-0.0588824838445026,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-nano",-0.0250348898360654,-0.0414902816712807,-0.00827911811181509,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-3.3-70B-Instruct-Turbo",-0.0367975684741771,-0.0527391231870175,-0.0212156608880668,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-4-Scout-17B-16E-Instruct",-0.0433406763817327,-0.0588320867851055,-0.0271953067859552,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","magistral-medium-2506",-0.073371518348502,-0.0911105446893698,-0.0545588115028185,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Meta-Llama-3-8B-Instruct-Lite",-0.0576789819882629,-0.0746569790850329,-0.0405957360329319,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-medium-latest",-0.0109991080633801,-0.0262811563941747,0.0045854784543441,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-small",-0.00915439217986203,-0.0248085900754032,0.00705071823288571,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","o4-mini",-0.00912285056206008,-0.0245459761394923,0.00687204128783839,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Qwen2.5-72B-Instruct-Turbo",-0.0132768517353641,-0.0303102247365322,0.00231652820948191,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","QwQ-32B",-0.0369884911568423,-0.0533747612250125,-0.0206703211024269,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1",0.0621146447603543,0.0489138793463616,0.0755019446953242,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-haiku-20240307",0.030787351354461,0.0193125734469117,0.0437103080159704,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-opus-20240229",0.0105798281943765,-0.00233470026616155,0.0227275873988727,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-sonnet-4-20250514",0.010659795334894,-0.00231788507172267,0.0231762151725248,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1",-0.0163755603198091,-0.0303599897031835,-0.00275026782864717,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1-0528-tput",0.00386195442623183,-0.00924584374613872,0.0163006041011233,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-1.5-pro",0.0608007864543306,0.0471099554908915,0.0743632698835011,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-2.5-flash",0.0436533343356998,0.0307096040924101,0.0566069680404558,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-2-27b-it",0.0388438201104395,0.0269313698659526,0.0523575950038693,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-3n-E4B-it",0.0271015095222523,0.0134904196375236,0.0404097601545049,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-mini",0.114388384728338,0.102110645841565,0.127762876270512,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-nano",0.0981232670351275,0.0839441102263327,0.112018162971873,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-3.3-70B-Instruct-Turbo",0.0281929452910794,0.0145407504165963,0.0424116386568705,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-4-Scout-17B-16E-Instruct",0.0287246706932105,0.0152761425104315,0.0419923987496264,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","magistral-medium-2506",-0.0325232409072256,-0.0456604531517392,-0.0178331858673056,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Meta-Llama-3-8B-Instruct-Lite",0.0435544894788714,0.030452833072953,0.0572141899506319,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-medium-latest",0.0189164123192483,0.00556611477792748,0.0309671206297299,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-small",0.015203799643445,0.0014498606107703,0.0281287157517579,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","o4-mini",0.0341541426838412,0.0213611613444287,0.047651193922947,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Qwen2.5-72B-Instruct-Turbo",0.0277381711779821,0.0144668287617297,0.0403058960164477,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","QwQ-32B",0.032925027165866,0.0204326231595326,0.0460247896570539,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1",-0.040521349175469,-0.0577151184100129,-0.0215630936801936,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-haiku-20240307",-0.124668193953052,-0.14279084845695,-0.107595208862329,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-opus-20240229",-0.0701766206112423,-0.0895304312043586,-0.0518670270364684,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-sonnet-4-20250514",-0.0837997535245895,-0.100799495906426,-0.065332732599188,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1",-0.0137925397040588,-0.0310301869780827,0.00455034088793637,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1-0528-tput",-0.0215281805831387,-0.0393225266550996,-0.00261966660243545,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-1.5-pro",-0.0140593552576105,-0.0332890849971593,0.00408132599743837,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-2.5-flash",-0.0174610503262416,-0.0362964400965044,-0.00141324025458433,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-2-27b-it",-0.0127138669242836,-0.0322461205728797,0.00517910804839346,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-3n-E4B-it",-0.0345333765690875,-0.0523542946679365,-0.0154483089180742,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-mini",-0.0703501898711953,-0.0868778251842469,-0.0522475423421282,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-nano",-0.0637319442810315,-0.0813799487591274,-0.0461929732952178,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-3.3-70B-Instruct-Turbo",-0.032211489746479,-0.0495542173291436,-0.014017154562923,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-4-Scout-17B-16E-Instruct",-0.0447590736299762,-0.0622596615823032,-0.0266020634141751,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","magistral-medium-2506",-0.0442205274624317,-0.0635502104594291,-0.0253356134139272,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Meta-Llama-3-8B-Instruct-Lite",-0.0648537491056325,-0.0832068632994061,-0.047354960870524,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-medium-latest",-0.0251909618122066,-0.0444070392499231,-0.00651576315539425,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-small",-0.0357548189051314,-0.0545515917127549,-0.0173020953660524,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","o4-mini",-0.0329406086182665,-0.0516694744752285,-0.0137776683996647,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Qwen2.5-72B-Instruct-Turbo",-0.0269948835550337,-0.0444805491182485,-0.00901782654190887,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","QwQ-32B",-0.0487976934842811,-0.067875010470185,-0.0307845414491987,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1",0.043245878358533,0.0314415578854351,0.055832586215274,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-haiku-20240307",0.00508382753521264,-0.00674182539103949,0.0178252878982801,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-opus-20240229",-0.00842982774707146,-0.02196217614148,0.00403545038485671,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-sonnet-4-20250514",-0.00186331346604018,-0.0137972035683124,0.00979679246586871,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1",-0.0223143777422461,-0.0348373379904089,-0.0104345154730915,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1-0528-tput",-0.00280940613583303,-0.0159365434867445,0.00920224904227815,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-1.5-pro",0.0316952621592492,0.0185272140969989,0.0433276959443462,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-2.5-flash",0.0250601945508286,0.0127247905694037,0.0377604669861615,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-2-27b-it",0.0204813292344068,0.00790511679451584,0.0340137715937795,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-3n-E4B-it",0.0182153911311471,0.00682879028760136,0.0304739829444621,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-mini",0.0865402245175634,0.0742989404905182,0.0980890256362801,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-nano",0.050935100819673,0.03919584810252,0.0628161327004735,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-3.3-70B-Instruct-Turbo",0.0143722670751151,0.00274122716445118,0.0271620589599417,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-4-Scout-17B-16E-Instruct",0.0167400207939109,0.00383357920717506,0.0291788654829572,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","magistral-medium-2506",-0.03249595088549,-0.045969494651291,-0.0198251557833051,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Meta-Llama-3-8B-Instruct-Lite",0.026274296239436,0.0134172124678395,0.0383168448847765,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-medium-latest",0.00165251091783969,-0.0105653196792539,0.0130167864051473,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-small",-0.00458345489345646,-0.0167909292333374,0.00818167908892087,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","o4-mini",0.027999264468383,0.0161250833329394,0.0407993839309638,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Qwen2.5-72B-Instruct-Turbo",0.00327468316627977,-0.00902117664666984,0.0159818598955961,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","QwQ-32B",0.0201249620596589,0.00864843849527979,0.0322407612676201,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1",-0.0595796390631727,-0.0688183969238851,-0.0507782204260242,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-haiku-20240307",-0.055299705281692,-0.0635266008285468,-0.0457820074888861,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-opus-20240229",-0.0452467762529254,-0.0540009161174978,-0.0356015776642107,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-sonnet-4-20250514",-0.0559466473067953,-0.0649963084364232,-0.0465164805379516,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1",-0.0439095449880691,-0.0523184846635709,-0.0344015323571969,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1-0528-tput",-0.037244549203749,-0.0465992635774462,-0.0286704512294802,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-1.5-pro",-0.0209895167213127,-0.0311802449592581,-0.0119298107864601,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-2.5-flash",-0.0466714761465733,-0.055309016479476,-0.0374911737491224,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-2-27b-it",-0.0268341613714794,-0.0361377695522989,-0.017690834909345,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-3n-E4B-it",-0.0411358137704924,-0.0503383754919599,-0.0314929339940044,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-mini",-0.0445772497892236,-0.0539195767707882,-0.0355647555456223,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-nano",-0.04931320714286,-0.058061126984182,-0.0402214236775295,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-3.3-70B-Instruct-Turbo",-0.0302910492018809,-0.0389597819183543,-0.0207735553877813,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-4-Scout-17B-16E-Instruct",-0.0281964580562064,-0.0370791850755808,-0.019259964270364,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","magistral-medium-2506",-0.0387457222807346,-0.0486503976637049,-0.0294531221357346,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Meta-Llama-3-8B-Instruct-Lite",-0.0351001883098576,-0.0444312242842277,-0.025808182136641,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-medium-latest",-0.0394095488732406,-0.0484610227322671,-0.0302985477501698,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-small",-0.0362916728222278,-0.0456420168096167,-0.0274072549009452,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","o4-mini",-0.0277311534426224,-0.0370988257142837,-0.0189373643781522,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Qwen2.5-72B-Instruct-Turbo",-0.0384191098829061,-0.0472017944937013,-0.0292563665241467,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","QwQ-32B",-0.0394845790169649,-0.0487247402336457,-0.0298708819784831,"respect_experimental"
