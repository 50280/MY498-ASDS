"term","contrast","model_name","estimate","conf.low","conf.high","attribute"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1",-0.0900817306487104,-0.109873693017675,-0.0697486049375641,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-haiku-20240307",-0.103142254363851,-0.121672531788592,-0.0846024594922926,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-opus-20240229",-0.0888788728524592,-0.108998382047076,-0.0689829021649997,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-sonnet-4-20250514",-0.126755744791569,-0.145154610977782,-0.108875243014288,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1",-0.0691941003723147,-0.0893022363281093,-0.0494251149321429,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1-0528-tput",-0.0521829518758797,-0.0704863662802626,-0.0336432795443508,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-1.5-pro",-0.0108847938992992,-0.0319116140870331,0.011623536951221,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-2.5-flash",-0.0663947005271883,-0.0836467549055177,-0.0480609028959473,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-2-27b-it",-0.038829908276491,-0.0562913545604751,-0.0220778799556158,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-3n-E4B-it",-0.0687344399063226,-0.0845504763117572,-0.0517412125087985,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-mini",-0.0678810311545671,-0.0884506586123995,-0.0465437442195753,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-nano",-0.0816785126674482,-0.103044092010503,-0.061215739919803,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-3.3-70B-Instruct-Turbo",-0.0511850984976517,-0.0688990351438198,-0.0343233417970228,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-4-Scout-17B-16E-Instruct",-0.0549612910140521,-0.0715272163122476,-0.036208465029934,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","magistral-medium-2506",-0.059193965322518,-0.0879850574007586,-0.0323447149244037,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Meta-Llama-3-8B-Instruct-Lite",-0.0738927160469484,-0.0939677802709886,-0.0538666120368226,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-medium-latest",-0.057822409694835,-0.0766236351317252,-0.0391551306750461,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-small",-0.0449806318975171,-0.0634364418108606,-0.0252499691978071,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","o4-mini",-0.0494392690444984,-0.0681704098969296,-0.0280884012907668,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Qwen2.5-72B-Instruct-Turbo",-0.0490746568407512,-0.0671992990972072,-0.0303418731290021,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","QwQ-32B",-0.06109953124583,-0.0785356526491755,-0.044211450642561,"affinity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1",-0.0776370060491874,-0.0922731114192986,-0.0633374172380982,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-haiku-20240307",-0.0593276602065739,-0.0721596222067438,-0.0464470290247974,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-opus-20240229",-0.0494654557166285,-0.0631969751532844,-0.0352640458372168,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-sonnet-4-20250514",-0.0702924491053875,-0.0858575852032105,-0.0533251189220395,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1",-0.0424901011288786,-0.0569280272793844,-0.0272010110562091,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1-0528-tput",-0.0347376810023411,-0.0482761051758713,-0.0211608132380488,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-1.5-pro",-0.0288122102318511,-0.0432891355545335,-0.0133891535042155,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-2.5-flash",-0.037142901148938,-0.0516501726415151,-0.0229048802645187,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-2-27b-it",-0.0516487531314044,-0.0660822081406044,-0.0365857353780422,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-3n-E4B-it",-0.0498946888126464,-0.062848894078826,-0.0360865206129174,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-mini",-0.0550134369274011,-0.0713007131109566,-0.039092914768905,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-nano",-0.0834179394473076,-0.0986494577728393,-0.0679152296090013,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-3.3-70B-Instruct-Turbo",-0.0372661927722998,-0.0511903271679452,-0.02229967729623,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-4-Scout-17B-16E-Instruct",-0.0323093941053871,-0.0458271286283368,-0.0192968413351316,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","magistral-medium-2506",-0.0209989851383061,-0.03933492529938,-0.00227129763080899,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Meta-Llama-3-8B-Instruct-Lite",-0.0348040049999999,-0.051723045917595,-0.0162473549950333,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-medium-latest",-0.0585658241032866,-0.0723227920622915,-0.0451315003617796,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-small",-0.0519381844573737,-0.066511384647282,-0.0383658604199687,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","o4-mini",-0.0304803235433263,-0.0453500880871783,-0.0159709451341082,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Qwen2.5-72B-Instruct-Turbo",-0.0503922006580817,-0.0633157315141186,-0.0370350105238207,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","QwQ-32B",-0.053238616587284,-0.0661567446702045,-0.0397288827772835,"compassion_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1",-0.0228488394402822,-0.0389499560337998,-0.00655948567155018,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-haiku-20240307",-0.0513781617793421,-0.0671181212167011,-0.035473471990368,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-opus-20240229",-0.0468666117892261,-0.0648020115786605,-0.0310551240322774,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-sonnet-4-20250514",-0.0741384632084301,-0.0895329189970108,-0.0585433507025613,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1",-0.0204663701789964,-0.0352933843280705,-0.00599335563766182,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1-0528-tput",-0.0228076093910999,-0.0378781316712415,-0.00856602689398387,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-1.5-pro",0.0390308384215442,0.0212212778618956,0.0576283820523936,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-2.5-flash",-0.0117731357541362,-0.0289427165129625,0.00314070244586653,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-2-27b-it",-0.0353442161638972,-0.0511107900007323,-0.020230472534274,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-3n-E4B-it",-0.0710090442014034,-0.0860043810149766,-0.0554256122350138,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-mini",-0.0738556008524581,-0.0914412390895795,-0.0543494262931287,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-nano",-0.0250348898360649,-0.0459055787304136,-0.00408196681487861,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-3.3-70B-Instruct-Turbo",-0.0367975684741775,-0.0514915161122784,-0.0221742097065577,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-4-Scout-17B-16E-Instruct",-0.0433406763817322,-0.0587430117216476,-0.0266984795587144,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","magistral-medium-2506",-0.073829375657267,-0.0969200293261804,-0.0501126189065728,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Meta-Llama-3-8B-Instruct-Lite",-0.0576789819882629,-0.0742840371603543,-0.0411607002293108,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-medium-latest",-0.0109991080633792,-0.0247005354364646,0.00132738208265772,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-small",-0.00915450046862121,-0.0243202917807546,0.00669467878336082,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","o4-mini",-0.00912285056205964,-0.0248022662688601,0.00830704061733389,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Qwen2.5-72B-Instruct-Turbo",-0.0132768517353636,-0.028631579862434,0.00198731705508639,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","QwQ-32B",-0.0368959934499886,-0.0525654878070755,-0.0216917088823705,"curiosity_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1",0.0621146447611233,0.0449620755548503,0.0779021763216475,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-haiku-20240307",0.0307873513544611,0.0181666400276037,0.0439672622942581,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-opus-20240229",0.0105798281943801,-0.00176437487341963,0.0226422469715903,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-sonnet-4-20250514",0.0106597953348948,-0.000786377510530882,0.0206704448595396,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1",-0.0163755603198092,-0.0257973830286419,-0.00679357834785341,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1-0528-tput",0.00386195442623027,-0.00410216001236314,0.0113074455291692,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-1.5-pro",0.0608007864543337,0.0447807497028895,0.0754510353583918,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-2.5-flash",0.0436533343356984,0.0287205849259346,0.0569772641089403,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-2-27b-it",0.0385225644650924,0.0256724371905736,0.05008351794811,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-3n-E4B-it",0.0271015095222458,0.015941508619183,0.0368693991841419,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-mini",0.114388384728337,0.0976141674232664,0.13086149514235,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-nano",0.0981232670351303,0.0803782921839614,0.114564329782383,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-3.3-70B-Instruct-Turbo",0.0281929452910804,0.0150896952432266,0.0422190618053244,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-4-Scout-17B-16E-Instruct",0.0287246706932094,0.0174360566878705,0.0410682923308612,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","magistral-medium-2506",-0.0325481379333014,-0.0467787969614193,-0.0180964513812405,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Meta-Llama-3-8B-Instruct-Lite",0.0435544894788734,0.0241165733149927,0.0633016547702634,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-medium-latest",0.018916412319249,0.00789356009523127,0.0296269183088434,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-small",0.0149501877077742,0.0036453986123107,0.0255295428899621,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","o4-mini",0.0341541426838433,0.0173150070546392,0.0493354195678114,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Qwen2.5-72B-Instruct-Turbo",0.0277381711779878,0.0171877956542604,0.0388945559260312,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","QwQ-32B",0.0330547025334349,0.0237693136077626,0.0424852369000223,"nuance_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1",-0.0405213491756328,-0.0606338604861449,-0.0194620202419701,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-haiku-20240307",-0.124668193953052,-0.145749221716075,-0.101298494203902,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-opus-20240229",-0.0701766206112407,-0.0922141875108389,-0.0476908091388075,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-sonnet-4-20250514",-0.0837997535245895,-0.102132697225575,-0.0649609018285264,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1",-0.0137925397040563,-0.0290216079597718,0.000887786677956888,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1-0528-tput",-0.0215281805831399,-0.0375933576393466,-0.00594903496781203,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-1.5-pro",-0.0140593552576135,-0.0325324046519609,0.00329488177773779,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-2.5-flash",-0.0174610503262415,-0.034616994396515,-0.000249347527564033,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-2-27b-it",-0.0132760979584416,-0.0316425814284819,0.00703931663459474,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-3n-E4B-it",-0.0345333765690843,-0.0517531744178192,-0.0186512130868927,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-mini",-0.0703501898711941,-0.091411647089154,-0.0492247761768794,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-nano",-0.0637319442810318,-0.0834770900205558,-0.0418937777391952,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-3.3-70B-Instruct-Turbo",-0.0322114897464792,-0.0483799826673206,-0.0146610804891629,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-4-Scout-17B-16E-Instruct",-0.0447590736299768,-0.0630571890314691,-0.0256398125204883,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","magistral-medium-2506",-0.0445901246571047,-0.0673557532133437,-0.0208669982227864,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Meta-Llama-3-8B-Instruct-Lite",-0.0648537491056344,-0.0820924371295759,-0.0450182118869999,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-medium-latest",-0.0251909618122058,-0.0404729993456886,-0.00896453480076945,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-small",-0.036121878596879,-0.0549055382562482,-0.0173852262554315,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","o4-mini",-0.0329406086182704,-0.0509286928795608,-0.0142232604119939,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Qwen2.5-72B-Instruct-Turbo",-0.0269948835550374,-0.0421546041842245,-0.00929383895601825,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","QwQ-32B",-0.0489113163121508,-0.0652553007037217,-0.0327042682656729,"personal_story_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1",0.0432458783583166,0.0288854642331835,0.0583768735542853,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-haiku-20240307",0.00508382753521208,-0.00487624380752297,0.0148961138106262,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-opus-20240229",-0.00842982774707179,-0.0183750212935974,0.00143448181559254,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-sonnet-4-20250514",-0.00186331346604185,-0.0111848494530293,0.0078154650867207,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1",-0.0223143777422435,-0.0307827569229209,-0.0133892439640795,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1-0528-tput",-0.00280940613583092,-0.00977478149676439,0.00477267980614702,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-1.5-pro",0.0316952621592529,0.0185715755306108,0.0445967055815086,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-2.5-flash",0.0250601945508283,0.0138727061028363,0.0372081979567463,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-2-27b-it",0.0201755533018197,0.00907375824198145,0.0319682565309079,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-3n-E4B-it",0.0182153911311461,0.00934840807102343,0.0276172606109955,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-mini",0.0865402245175642,0.0712668463579935,0.103027071680366,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-nano",0.0509351008196728,0.0346084205046294,0.0666279002910285,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-3.3-70B-Instruct-Turbo",0.0143722670751173,0.00199315636653745,0.0276482304171322,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-4-Scout-17B-16E-Instruct",0.0167400207939116,0.00588957958542018,0.0281012427697814,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","magistral-medium-2506",-0.0325470839625932,-0.0449931027815402,-0.0200064169682482,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Meta-Llama-3-8B-Instruct-Lite",0.0262742962394369,0.0074291791570239,0.0451472791389293,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-medium-latest",0.00165251091784036,-0.00763066182555116,0.0110711324458846,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-small",-0.00480270963372509,-0.0131127222019744,0.00322510155204104,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","o4-mini",0.0279992644683853,0.0107141827479715,0.0459475469753747,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Qwen2.5-72B-Instruct-Turbo",0.00327468316627821,-0.00593659796316403,0.012914352516695,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","QwQ-32B",0.0203933768518755,0.0117246601708554,0.0291828597819191,"reasoning_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1",-0.0595796390632344,-0.0700337267811043,-0.0492679658769713,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-haiku-20240307",-0.0552997052816908,-0.0646099487834717,-0.045955093372625,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-3-opus-20240229",-0.0452467762529279,-0.0554570345703732,-0.0359738478592727,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","claude-sonnet-4-20250514",-0.0559466473067921,-0.0663031994609296,-0.0458053394634449,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1",-0.0439095449880671,-0.0533234590505366,-0.0345436253422346,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","DeepSeek-R1-0528-tput",-0.0372445492037465,-0.0468856518174887,-0.0285310311227505,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-1.5-pro",-0.0209895167213127,-0.0311387439490544,-0.0107381686461928,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemini-2.5-flash",-0.0466714761465732,-0.0557134989442109,-0.0375447746971612,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-2-27b-it",-0.0274430118763973,-0.0358903159225448,-0.0185672411852945,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gemma-3n-E4B-it",-0.0411358137704915,-0.0497297478075224,-0.0324915709223147,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-mini",-0.0445772497892276,-0.0543278551767633,-0.0346691064391778,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","gpt-4.1-nano",-0.0493132071428575,-0.0591810594543413,-0.0396897607196912,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-3.3-70B-Instruct-Turbo",-0.0302910492018772,-0.0389655410645518,-0.0212668326469107,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Llama-4-Scout-17B-16E-Instruct",-0.0281964580562065,-0.0376026296662469,-0.0191724925276905,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","magistral-medium-2506",-0.0388081436387132,-0.0508787786692266,-0.0272538484017527,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Meta-Llama-3-8B-Instruct-Lite",-0.0351001883098592,-0.0459508968544785,-0.0246157318061064,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-medium-latest",-0.0394095488732394,-0.0483956619068051,-0.0307307014690059,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","mistral-small",-0.0357755747244975,-0.0455356058669404,-0.0257665287929182,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","o4-mini",-0.0277311534426243,-0.0366471768599936,-0.0189663809043371,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","Qwen2.5-72B-Instruct-Turbo",-0.0384191098829054,-0.0463967579827754,-0.0305398606468585,"respect_experimental"
"model_fed_q_type","whathow_q - hobsons_c","QwQ-32B",-0.039436488269123,-0.0482544854508572,-0.0315339941600718,"respect_experimental"
